{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b402a9c-84ec-4818-ab34-967764d3f6fc",
   "metadata": {
    "name": "Intro",
    "collapsed": false
   },
   "source": "# âš½âš¾ðŸ¥Ž **HOL: Olympic Games Data Hub** ðŸ¥‡ðŸ¥ˆðŸ¥‰\n\n---\n\nWelcome to the **Olympic Games Data Hub**! In this notebook, we will use Python functions and External Access Integration to load and analyze data about the Olympics from 1896 to 2022. Our data source is a GitHub repository, from which we'll fetch and directly store historical Olympic data in our Snowflake account. No S3 buckets or local downloads are needed â€” our goal is to simplify the execution of this Hands-On Lab (HOL) while showcasing the extensive capabilities of Snowflake!\n\n### What We'll Do:\n1. **Load Data**: Fetch Olympic data from the GitHub repository.\n2. **Analyze Data**: Utilize Snowpark DataFrames for data preparation and analysis.\n3. **Visualize Insights**: Build interactive dashboards with Streamlit for comprehensive analytics.\n\n![Olympic Rings](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Olympic_rings_without_rims.svg/640px-Olympic_rings_without_rims.svg.png)\n\n---\n\nDive into the code below to start exploring and analyzing the fascinating world of the Olympics!\n"
  },
  {
   "cell_type": "markdown",
   "id": "898f2e7c-3f14-41a1-baeb-c1a48579f43e",
   "metadata": {
    "name": "Pre_Reqs",
    "collapsed": false
   },
   "source": "### Setup\n\nBefore using this notebook, ensure that you have created the following objects by running the `setup.sql` script in a worksheet:\n\n- **Database**: `OLYMPIC_GAMES`\n- **Schema**: `RAW_DATA`\n- **Warehouse**: `OLYMPICS_GAMES_WH`\n- **Network Rule**: `GITHUB_NETWORK_RULE`\n- **External Access Integration**: `GITHUB_EXTERNAL_ACCESS_INTEGRATION`\n\nThe first three items are required as you will need to define the Database, Schema, and Warehouse when you import this notebook into the Snowflake UI.\n\nFor the **Network Rule** and **External Access Integration**, once created, follow these steps to make them available within this notebook:\n\n1. **Click on Notebook Settings** (located at the top right of the worksheet screen).\n2. **Select the External Access Tab**.\n3. **Enable** `GITHUB_EXTERNAL_ACCESS_INTEGRATION` from the list.\n4. **Reload the Notebook**. Once reloaded, you will have access to the GitHub URL directly from this notebook.\n\nWith these configurations in place, youâ€™ll be ready to extract and work with the dataset from the external GitHub URL in the following cells.\n\n---\n"
  },
  {
   "cell_type": "code",
   "id": "9908f3ab-97f1-4610-8674-8655b80862d3",
   "metadata": {
    "language": "python",
    "name": "Get_Active_Session",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark import Session\n\nsession = get_active_session()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e00475bc-49df-4635-bd32-f4c8eb4c8225",
   "metadata": {
    "language": "sql",
    "name": "Use_Role_Enforcement",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Note: For this Hands-On Lab (HOL), we are not creating ad hoc roles and users to minimize prerequisites and simplify setup.\n\nUSE ROLE ACCOUNTADMIN;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "208cbcf7-db40-4a95-8f53-518bb1fe92a1",
   "metadata": {
    "language": "python",
    "name": "Create_Fetch_Data_Function",
    "collapsed": false
   },
   "outputs": [],
   "source": "import requests\nimport pandas as pd\nfrom snowflake.snowpark import DataFrame as df\nfrom io import StringIO\n\ndef fetch_dataset_from_github(url: str) -> 'DataFrame':\n    # Fetch the CSV data from the URL\n    response = requests.get(url)\n    if response.status_code == 200:\n        # Decode the content and read into a Pandas DataFrame\n        csv_data = response.content.decode('utf-8')\n        csv_file = StringIO(csv_data)\n        pandas_df = pd.read_csv(csv_file)\n        \n        # Convert Pandas DataFrame to Snowpark DataFrame\n        return session.create_dataframe(pandas_df)\n    else:\n        raise Exception(f\"Failed to fetch CSV: {response.status_code} - {response.text}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "00876816-7aa0-4300-8373-5de754927d78",
   "metadata": {
    "language": "python",
    "name": "Load_All_Data",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.functions import col\n\n# Function to rename columns to uppercase\ndef rename_columns_to_uppercase(df):\n    # Generate a list of columns with uppercase names\n    new_columns = [col(c).alias(c.upper()) for c in df.columns]\n    # Select columns with new names\n    return df.select(*new_columns)\n\n# Base URL and list of files\nurl_base = 'https://github.com/sfc-gh-mconsoli/olympic_games_data_hub/raw/main/dataset/'\nurl_files = [\n    'Olympic_Games.csv',\n    'Olympic_Athlete_Bio.csv',\n    'Olympic_Results.csv',\n    'Olympic_Athlete_Event_Results.csv',\n    'Olympic_Country.csv',\n    'Olympic_Games_Medal_Tally.csv'\n]\n\n# Loop through each URL\nfor url in url_files:\n    # Get Snowpark DataFrame from the URL\n    df = fetch_dataset_from_github(url_base + url)\n\n    # Extract table name from URL\n    table_name = url.split('/')[-1].replace('.csv', '').upper()\n\n    # Drop the table if it exists\n    session.sql(f\"DROP TABLE IF EXISTS {table_name}\").collect()\n\n    # Convert column names to uppercase\n    df = rename_columns_to_uppercase(df)\n\n    # Create table and insert data from Snowpark DataFrame\n    df.write.save_as_table(table_name, mode='overwrite')\n\n    print(f\"Table {table_name} created and data loaded successfully.\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc221afd-5cf4-4877-81f2-341b5a794274",
   "metadata": {
    "language": "python",
    "name": "Verify_Data_Loaded_1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Let's check loaded data\n\nsession.table('OLYMPIC_GAMES_MEDAL_TALLY').limit(51)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db058f60-3e5b-4a2f-863d-5aa0ff228e59",
   "metadata": {
    "language": "sql",
    "name": "Verify_Data_Loaded_2",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- No surprise, the tallest are the basketball players! :D \nSELECT * FROM \nOLYMPIC_GAMES.RAW_DATA.OLYMPIC_ATHLETE_BIO\nWHERE COUNTRY like '%Italy%' and HEIGHT > 180 \norder by HEIGHT DESC\nLIMIT 50",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d80c942b-3f67-4594-b779-4ec271a57374",
   "metadata": {
    "language": "python",
    "name": "Gold_Medals_Analysis",
    "collapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\nimport snowflake.snowpark as sp\n\n# Load the Snowpark DataFrame from the table\ndf = session.table('OLYMPIC_GAMES_MEDAL_TALLY')\n\n# Aggregate gold medals per country\ngold_medals_df = df.group_by(\"COUNTRY\").agg(sp.functions.sum(\"GOLD\")\n                .alias(\"TOTAL_GOLD_MEDALS\")).limit(10)\n\n# Collect the data as a list of dictionaries\ndata = gold_medals_df.collect()\ndata_list = [row.as_dict() for row in data]\n\n# Convert the list of dictionaries into two lists: one for labels and one for values\ncountries = [row['COUNTRY'] for row in data_list]\ngold_medals = [row['TOTAL_GOLD_MEDALS'] for row in data_list]\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9be3585a-985e-484a-b330-dea12b9f9ad5",
   "metadata": {
    "language": "python",
    "name": "Streamlit_in_Notebooks",
    "collapsed": false
   },
   "outputs": [],
   "source": "import plotly.graph_objects as go\n\n# Streamlit app\nst.title(\"Olympic Games Medal Tally\")\n\n# Pie chart using Plotly\nst.subheader(\"Countries with the Most Gold Medals\")\nfig = go.Figure(data=[go.Pie(labels=countries, values=gold_medals, hole=0.3)])\nfig.update_layout(margin=dict(t=0, b=0, l=0, r=0), title_text=\"Gold Medals by Country\")\nst.plotly_chart(fig)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a7f1d38-0652-4171-8841-6736eb402ece",
   "metadata": {
    "name": "Moving_to_Streamlit",
    "collapsed": false
   },
   "source": "### ðŸš€ Elevate Your Experience\n\nThis notebook has been great so far, but letâ€™s take it to the next level! In the following steps, we will integrate the Streamlit app into Snowflake. Hereâ€™s how you can do it:\n\n1. **Download the Streamlit App Script**\n   - Get the [`olympic_games_data_hub.py`](https://github.com/sfc-gh-mconsoli/olympic_games_data_hub) file from the GitHub repository.\n\n2. **Create a Streamlit App in Snowsight Projects**\n   - Navigate to **Snowsight Projects**.\n   - Create a new **Streamlit App** and import the downloaded file.\n\n3. **Explore and Analyze**\n   - Once imported, the app will be ready to go!\n   - Feel free to dive deeper into the data, either through this notebook or by exploring the Streamlit app.\n\nEnjoy exploring and analyzing the Olympic Games data!\n"
  }
 ]
}